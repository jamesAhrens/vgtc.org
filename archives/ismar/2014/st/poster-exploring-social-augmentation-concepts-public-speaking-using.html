---
title: [Poster] Exploring Social Augmentation Concepts for Public Speaking using Peripheral Feedback and Real-Time Behavior Analysis
layout: default
permalink: /archives/ismar/2014/st/poster-exploring-social-augmentation-concepts-public-speaking-using
breadcrumb:
  - ['Home', '/']
  - ['conference archives', '/archives']
  - ['ISMAR', '/archives/ismar']
  - ['2014', '/archives/ismar/2014']
  - ['S&amp;T Posters', '/archives/ismar/2014/st/posters']
---


  

      <span property="dc:title" content="[Poster] Exploring Social Augmentation Concepts for Public Speaking using Peripheral Feedback and Real-Time Behavior Analysis" class="rdf-meta element-hidden"></span>

  

  <div class="content">

    <div class="field field-name-field-authors field-type-text field-label-above"><div class="field-label">Authors:&nbsp;</div><div class="field-items"><div class="field-item even">Lonut Damian, Chiew Seng Sean Tan, Tobias Baur, Johannes Schoning, Kris Luyten, Elisabeth Andre</div></div></div><div class="field field-name-field-doi-bookmark field-type-link-field field-label-above"><div class="field-label">DOI Bookmark:&nbsp;</div><div class="field-items"><div class="field-item even"><a href="http://dx.doi.org/10.1109/ismar.2014.6948440">http://dx.doi.org/10.1109/ismar.2014.6948440</a></div></div></div><div class="field-label">Abstract:&nbsp;</div>Non-photorealistic rendering (NPR) has been shown as a powerful way to enhance both visual coherence and immersion in augmented reality (AR). However, it has only been evaluated in idealized pre-rendered scenarios with handheld AR devices. In this paper we investigate the use of NPR in an immersive, stereoscopic, wide field-of-view head-mounted video see-through AR display. This is a demanding scenario, which introduces many real-world effects including latency, tracking failures, optical artifacts and mismatches in lighting. We present the AR-Rift, a low-cost video see-through AR system using an Oculus Rift and consumer webcams. We investigate the themes of consistency and immersion as measures of psychophysical non-mediation. An experiment measures discernability and presence in three visual modes: conventional (unprocessed video and graphics), stylized (edge-enhancement) and virtualized (edge-enhancement and color extraction). The stylized mode results in chance-level discernability judgments, indicating successful integration of virtual content to form a visually coherent scene. Conventional and virutalized rendering bias judgments towards correct or incorrect respectively. Presence as it may apply to immersive AR, and which, measured both behaviorally and subjectively, is seen to be similarly high over all three conditions.<div id="disqus_thread"><noscript><p><a href="http://vgtc.disqus.com/?url=http%3A%2F%2Fvgtc.org%2Farchives%2Fismar%2F2014%2Fst%2Fposter-exploring-social-augmentation-concepts-public-speaking-using">View the discussion thread.</a></p></noscript></div>  </div>

